{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "every-hello",
   "metadata": {},
   "source": [
    "This second notebook takes in each output from the zonal stats tasks, and reshapes each dataset into long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "falling-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../src\")  # relative path where the library is stored\n",
    "# alternatively sys.path.append('C/Users/wb514197/Repos/GEE_Zonal/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "congressional-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "excited-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_landsat(file_path):\n",
    "    df = pd.read_csv(file_path, index_col=0)\n",
    "    #     df.reset_index(drop=True, inplace=True)\n",
    "    df.drop(columns=\".geo\", inplace=True)\n",
    "    #     df.loc[:, \"n_null\"] = df.apply(lambda x: x.isna().sum(), axis=1)\n",
    "\n",
    "    file = os.path.basename(file_path)\n",
    "    lc_id, var, temp_stat = file.replace(\".csv\", \"\").split(\"_\")\n",
    "    var_name = var.upper()\n",
    "    var = \"_\".join([var, temp_stat])\n",
    "    stubs = [\"_\".join([var, a]) for a in temp_stats]\n",
    "\n",
    "    def rename_func(col):\n",
    "        if var_name in col:\n",
    "            p = col.split(\"_\")\n",
    "            new_name = p[1] + \"_\" + p[2] + \"_\" + p[3] + \"__\" + p[0]\n",
    "            return new_name\n",
    "        else:\n",
    "            return col\n",
    "\n",
    "    df.rename(rename_func, axis=1, inplace=True)\n",
    "    df.rename(str.lower, axis=1, inplace=True)\n",
    "\n",
    "    df_re = pd.wide_to_long(df, stubnames=stubs, i=\"wb_adm0_na\", j=\"year\", sep=\"__\")\n",
    "\n",
    "    return df_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cordless-terrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_collection(lc_id, files_dir):\n",
    "    files = glob.glob(files_dir + f\"/{lc_id}*\")\n",
    "    l_processed = [process_file_landsat(file) for file in files]\n",
    "    l_all = pd.concat(l_processed, axis=1)\n",
    "    l_all = l_all.loc[:, ~l_all.columns.duplicated()].copy()\n",
    "    l_all.loc[:, \"landsat_id\"] = lc_id\n",
    "    return l_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-trigger",
   "metadata": {},
   "source": [
    "## NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ancient-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_stats = [\"mean\", \"max\", \"min\", \"stddev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stock-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"X:/data/ee\")\n",
    "ndvi_dir = os.path.join(data_dir, \"ndvi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "early-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_ids = [\"LT05\", \"LE07\", \"LC08\"]\n",
    "# lc_ids = [\"LE07\",\"LC08\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "starting-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [process_collection(lc_id, ndvi_dir) for lc_id in lc_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "complicated-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = pd.concat(res, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sufficient-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join(data_dir, \"output\")\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "subjective-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndvi.to_csv(os.path.join(out_dir, \"ndvi.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-ticket",
   "metadata": {},
   "source": [
    "## EVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "conditional-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "evi_dir = os.path.join(data_dir, \"evi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rural-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [process_collection(lc_id, evi_dir) for lc_id in lc_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "incorporated-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "evi = pd.concat(res, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "destroyed-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evi.to_csv(os.path.join(out_dir, \"evi.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-ceiling",
   "metadata": {},
   "source": [
    "## NDSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "white-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndsi_dir = os.path.join(data_dir, \"ndsi\")\n",
    "res = [process_collection(lc_id, ndsi_dir) for lc_id in lc_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "affected-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndsi = pd.concat(res, axis=0)\n",
    "# ndsi.to_csv(os.path.join(out_dir, \"ndsi.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-poverty",
   "metadata": {},
   "source": [
    "## NDWI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "radio-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndwi_dir = os.path.join(data_dir, \"ndwi\")\n",
    "res = [process_collection(lc_id, ndwi_dir) for lc_id in lc_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ongoing-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndwi = pd.concat(res, axis=0)\n",
    "# ndwi.to_csv(os.path.join(out_dir, \"ndwi.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-validation",
   "metadata": {},
   "source": [
    "## Chirps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "relative-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "chirps_dir = os.path.join(data_dir, \"chirps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "thorough-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_all = pd.read_csv(os.path.join(chirps_dir, \"chirps.csv\"))\n",
    "rain_sum = pd.read_csv(os.path.join(chirps_dir, \"chirps_sum.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "rotary-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_func(col):\n",
    "    if \"precipitation\" in col:\n",
    "        new_name = col + \"_sum\"\n",
    "        return new_name\n",
    "    else:\n",
    "        return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "engaged-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_sum.rename(rename_func, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "verified-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_all = rain_all.join(\n",
    "    rain_sum.loc[\n",
    "        :, rain_sum.columns[[\"precipitation\" in col for col in rain_sum.columns]]\n",
    "    ],\n",
    "    how=\"outer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "hairy-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rain_all.copy()\n",
    "df.drop(columns=\".geo\", inplace=True)\n",
    "var_name = \"precipitation\"\n",
    "\n",
    "\n",
    "def rename_func(col):\n",
    "    if var_name in col:\n",
    "        p = col.split(\"_\")\n",
    "        new_name = p[1] + \"_\" + p[2] + \"_\" + p[3] + \"__\" + p[0]\n",
    "        return new_name\n",
    "    else:\n",
    "        return col\n",
    "\n",
    "\n",
    "df.rename(rename_func, axis=1, inplace=True)\n",
    "df.rename(str.lower, axis=1, inplace=True)\n",
    "var = \"precipitation_sum\"\n",
    "stats = temp_stats + [\"sum\"]\n",
    "stubs = [\"_\".join([var, a]) for a in stats]\n",
    "df_re = pd.wide_to_long(df, stubnames=stubs, i=\"wb_adm0_na\", j=\"year\", sep=\"__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "brief-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_re.to_csv(os.path.join(out_dir, \"chirps.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-plasma",
   "metadata": {},
   "source": [
    "## Lights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "included-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(files_dir, var_name):\n",
    "    files = glob.glob(files_dir + \"/*\")\n",
    "    l_processed = [process_file(file, var_name) for file in files]\n",
    "    l_all = pd.concat(l_processed, axis=1)\n",
    "    l_all = l_all.loc[:, ~l_all.columns.duplicated()].copy()\n",
    "    return l_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "disturbed-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path, var_name):\n",
    "    df = pd.read_csv(file_path, index_col=0)\n",
    "    df.drop(columns=\".geo\", inplace=True)\n",
    "\n",
    "    file = os.path.basename(file_path)\n",
    "    source, temp_stat = file.replace(\".csv\", \"\").split(\"_\")\n",
    "    var = \"_\".join([var_name, temp_stat])\n",
    "    stubs = [\"_\".join([var, a]) for a in temp_stats]\n",
    "\n",
    "    def rename_func(col):\n",
    "        if var_name in col or \"avg_rad\" in col:\n",
    "            p = col.split(\"_\")\n",
    "            if var_name == \"lights\":\n",
    "                new_name = \"lights\" + \"_\" + p[3] + \"_\" + p[4] + \"__\" + p[0]\n",
    "            elif var_name == \"temperature\":\n",
    "                new_name = \"temperature\" + \"_\" + p[3] + \"_\" + p[4] + \"__\" + p[0]\n",
    "            return new_name\n",
    "        else:\n",
    "            return col\n",
    "\n",
    "    df.rename(rename_func, axis=1, inplace=True)\n",
    "    df.rename(str.lower, axis=1, inplace=True)\n",
    "\n",
    "    df_re = pd.wide_to_long(df, stubnames=stubs, i=\"wb_adm0_na\", j=\"year\", sep=\"__\")\n",
    "\n",
    "    return df_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "blind-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmps_dir = os.path.join(data_dir, \"dmps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "blind-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmps = process_data(dmps_dir, \"lights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "violent-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dmps.to_csv(os.path.join(out_dir, \"dmps.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "confused-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "viirs_dir = os.path.join(data_dir, \"viirs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "accredited-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "viirs = process_data(viirs_dir, \"lights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "metallic-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# viirs.to_csv(os.path.join(out_dir, \"viirs.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-radio",
   "metadata": {},
   "source": [
    "## LST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "impressed-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_dir = os.path.join(data_dir, \"lst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "assumed-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = process_data(lst_dir, \"temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dirty-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst.to_csv(os.path.join(out_dir, \"temperature.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-navigation",
   "metadata": {},
   "source": [
    "## Cropland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "quarterly-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, \"cropland\", \"cropland.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "raised-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\".geo\", inplace=True)\n",
    "df.rename(str.lower, axis=1, inplace=True)\n",
    "df_re = pd.wide_to_long(df, stubnames=[\"cropland\"], i=\"wb_adm0_na\", j=\"year\", sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "rough-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re.to_csv(os.path.join(out_dir, \"cropland.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-length",
   "metadata": {},
   "source": [
    "## Impervious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "italic-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, \"impervious\", \"impervious.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "elementary-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\".geo\", inplace=True)\n",
    "df.rename(str.lower, axis=1, inplace=True)\n",
    "df_re = pd.wide_to_long(df, stubnames=[\"imperv\"], i=\"wb_adm0_na\", j=\"year\", sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "formal-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re.to_csv(os.path.join(out_dir, \"impervious.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Earth Engine",
   "language": "python",
   "name": "ee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
